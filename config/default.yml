##working directory for your experiment
work_dir: '/cluster/work/users/yingyue/qg'

directories:
  cycle_dir: '{work_dir}/cycle/{time:%Y%m%d%H%M}'
  forecast_dir: '{work_dir}/cycle/{time:%Y%m%d%H%M}/{model_name}'
  analysis_dir: '{work_dir}/cycle/{time:%Y%m%d%H%M}/analysis/{scale_dir}'

##python environment source script
python_env: '/cluster/home/yingyue/python.src'

job_submit:
  host: 'localhost'     ##machine name, laptop or supercomputer
  project:              ##project for resource allocation
  queue:                ##job queue name
  scheduler:            ##which scheduler is used on the machine
  run_separate_jobs: False  ##if true, submit each job separately to the scheduler
                            ##otherwise jobs will be run as steps in a shared job allocation

##number of processors to use for assimilation
nproc: 16

##some experiment design parameters
nens: 20            ##ensemble size
run_forecast: True  ##if true, run the ensemble forecast step
run_analysis: True  ##if true, run the analysis step
run_diagnose: True  ##if true, run the diagnose scripts
debug: False        ##if true, output debug data/message
timer: True         ##if true, output information on function runtime

##time control of the experiment
time_start: '202301010000'          ## start time of the experiment, format ccyymmddHHMM
time_end: '202302180000'            ## end time of the experiment
time_analysis_start: '202301010000' ## start time of the first analysis cycle
time_analysis_end: '202302180000'   ## end time of the last analysis cycle
cycle_period: 12                    ## cycle period, in hours

obs_time_steps: [0]              ## time steps defining observation window, hours, relative to cycle time
obs_time_scale: 0                ## smoothing window in hours for observations
state_time_steps: [0]            ## time steps defining the 4D state vector, hours, relative to cycle time
state_time_scale: 0              ## smoothing window in hours for state variables

##analysis grid definition, for now we support only uniform analysis grids
## if type==custom, configure a Grid.regular_grid
## if you want to use the model grid directly (if only 1 model is involved), set type==model_name
grid_def:
  type: 'custom'
  proj:
  xmin: -1                 ##coordinate range in x and y, use meter units but can be nondimensional too
  xmax: 257
  ymin: -1
  ymax: 257
  dx: 0.1                  ##grid spacing in coordinate units (resolution)
  centered: False
  distance_type: 'cartesian'    ## type of distance function (default: cartesian; or spherical from lat/lon coords)

z_coords_from: 'mean'       ##use ensemble 'mean' or 'member' z coords as reference of obs z location

##state vector definition (a list of definitions, one for each variable)
state_def:
- name: 'streamfunc'      ## name of the variable
  model_src: 'qg'         ## which model the variable come from
  var_type: 'field'       ## if 'field' the variable consists of 2D fields, if 'scalar' it is a number
  err_type: 'normal'      ## which error model to use, now only 'normal'

##observation definition (a list of definitions, one for each variable)
obs_def:
- name: 'streamfunc'      ## name of the variable
  dataset_src: 'qg'       ## which dataset module it comes from
  model_src: 'qg'         ## which model to use to compute observation priors
  ##the following is specific to the observation 'streamfunc' in the dataset
  nobs: 3000              ## number of observations (if generating synthetic obs)
  obs_window_min: -6      ## observation within the window (in hours) will be considered valid at cycle time
  obs_window_max: 0
  err:
    type: 'normal'        ## observation error model (normal, ...)
    std: 0.2              ## error standard deviation (in observation physical units)
  hroi: 100               ## horizontal localization radius (in grid coordinate units)
  vroi: 5                 ## vertical   ..            .. (vertical coordinate units)
  troi: 24                ## temporal   ..            .. (hours)
  impact_on_state:        ## a list of impact factor of this observation on state variables
    streamfunc: 1.0       ## unlisted state variable has a default of 1.0,
                          ## this can help removing the analysis increment only on certain variables

use_synthetic_obs: True  ## if true, use synthetic observations generated from truth
shuffle_obs: False       ## if true, shuffle the order of obs sequence

##dataset configuration dict(dataset_name, opts)
##will use config_file as starting point, additional variables will overwrite config_file settings
##if new variables introduced here, they will be appended to the configuration
dataset_def:
  qg:
    config_file: '/cluster/home/yingyue/code/NEDAS/dataset/qg/default.yml'  ##configuration file (empty for now)
    dataset_dir: '.'  ##path to the dataset files, for qg we use synthethic obs so no need to specify

##model configuration dict(model_name, opts)
##will use config_file as starting point, additional variables will overwrite config_file settings
##if new variables introduced here, they will be appended to the configuration
model_def:
  qg:
    config_file: '/cluster/home/yingyue/code/NEDAS/models/qg/default.yml'  ##configuration file
    model_env: '/cluster/home/yingyue/code/NEDAS/models/qg/env/setup_betzy.src'  ##source file to enter environment
    model_code_dir: '/cluster/home/yingyue/code/NEDAS/models/qg'           ##where to find model executable
    nproc_per_run: 1    ## number of processors for one model.run
    nproc_per_util: 1   ## number of processors for other utility funcs, model.preprocess, etc.
    walltime: 1000      ## walltime in seconds
    restart_dt: 12      ## restart file interval in hours
    forcing_dt: 12      ## boundary forcing interval
    ens_run_type: scheduler    ## 'scheduler' or 'batch', see ensemble_forecast.py for details
    use_job_array: False       ##if true, use job array in scheduler for ensemble runs
    ens_init_dir: '/cluster/work/users/yingyue/qg_ens_runs'   ##path to the initial ensemble restart files
    truth_dir: '/cluster/work/users/yingyue/qg/truth'         ##path to the truth files (for synthetic obs)
    

##perturbatio scheme (a list of individual perturbation methods can be set here)
perturb:
- variable: 'streamfunc'   ## which variable, or a list of variables to perturb
  model_src: 'qg'          ## which model the variable(s) come from
  type: 'gaussian'         ## type of perturbation (gaussian, powerlaw, displace, ...)
  amp: 1                   ## amplitude
  hcorr: 10                ## horizontal correlation length (in grid.x,y coordinate units)
  tcorr: 12                ## temporal correlation length (in hours)

##more details in assimilation algorithm
assim_mode: 'batch'        ##assimilation mode (batch or serial)
filter_type: 'ETKF'        ##filter type for the update (for batch: ETKF, DEnKF..., for serial: EAKF, RHF...)

##filter parameters
rfactor: 2                 ## inflation factor for observation error when updating ensemble perturbations
kfactor: 2                 ## inflation factor for observation error if innovation is too large
nlobs_max:                 ## maximum number of local observations to be assimilated (leave blank if using all obs)

##multiscale approach in assimilation
nscale: 1                    ## number of scale components
scale_id: 0                  ## current scale component index
decompose_obs: False         ## if true, decompose observations as well
character_length: [16]       ## characteristic length (in grid coord unit) for each scale (large to small)
localize_scale_fac: [1]      ## scale factor for localization distances
obs_err_scale_fac: [1]       ## scale factor for observation error variances

##alignment technique in assimilation
run_alignment: False         ## if true, run alignment technique
alignment:
  variable: 'streamfunc'     ## which variable the alignment is based on
  nlevel: 5                  ## number of resolution levels in multi-grid approach
  smoothness_weight: 1       ## weight in cost function to enforce smoothness of displace vector field

##covariance inflation technique in assimilation
inflation:
  type: 'posterior,RTPP'    ## type of inflation (posterior/prior, multiplicative/RTPP...)
  adaptive: True            ## if true, run an adaptive version of the inflation scheme
  coef: 1.0                 ## static inflation coefficient

##covariance localization technique in assimilation
## type of localization kernel (GC, step, exp, NICE...)
## specified for horizontal (h), vertical (v) and temporal (t) separately
## for distance-based localization, the radius of influence (roi) is specified in obs_def
localization:               ## localization is configured separately for horizontal, vertical and temporal relations
  horizontal: 'GC,NICE'          ## type of localization kernel (GC, step, exp, NICE...)
  vertical: 'GC'
  temporal: 'exp'

##diagnostic methods configuration
diag:
- method: 'misc.convert_output'  ## method name
  is_ensemble: False             ## if True, the method is applied to ensemble members
  config_file: '/cluster/home/yingyue/code/NEDAS/diag/misc/convert_output/default.yml'  ## configuration file
  model_src: 'qg'                ## which model the method is applied to
  variables: ['vorticity']       ## which variables the method is applied to
  grid_def:                      ## output grid definition, leave blank to use default.yml settings
  file: '/cluster/work/users/yingyue/qg/output/mem{member:03}_{time:%Y-%m-%dT%H}.nc'  ## output file format
